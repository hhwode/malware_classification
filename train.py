#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
@Project    : malware_classification
@File       : train.py
@IDE        : PyCharm
@Author     : Huang Hua
@Date       : 2021/9/6 20:07
"""
import torch
from torchvision import transforms
import torch.nn as nn
import torch.optim as opt
from torch.utils.data import DataLoader
import time
import models
import config
import h5py
from dataset.dataset import H5Dataset


def train_and_valid(model, loss_function, optimizer, epochs=25):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    record = []
    best_acc = 0.5
    best_epoch = 0

    for epoch in range(epochs):
        epoch_start = time.time()
        print("Epoch: {}/{}".format(epoch + 1, epochs))
        model.train()

        train_loss = 0.0
        train_acc = 0.0
        valid_loss = 0.0
        valid_acc = 0.0

        for i, (inputs, labels) in enumerate(train_loader):
            inputs = inputs.to(device).float()
            labels = labels.to(device).long()
            # inputs.unsqueeze_(0)
            # labels.unsqueeze_(0)
            # print(inputs, labels)
            #print(labels)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
            ret, predictions = torch.max(outputs.data, 1)
            correct_counts = predictions.eq(labels.data.view_as(predictions))
            acc = torch.mean(correct_counts.type(torch.FloatTensor))
            train_acc += acc.item() * inputs.size(0)

        with torch.no_grad():
            model.eval()
            for j, (inputs, labels) in enumerate(val_loader):
                inputs = inputs.to(device).float()
                labels = labels.to(device).long()
                outputs = model(inputs)
                loss = loss_function(outputs, labels)
                valid_loss += loss.item() * inputs.size(0)
                ret, predictions = torch.max(outputs.data, 1)
                correct_counts = predictions.eq(labels.data.view_as(predictions))
                acc = torch.mean(correct_counts.type(torch.FloatTensor))
                valid_acc += acc.item() * inputs.size(0)

        avg_train_loss = train_loss / train_data_size
        avg_train_acc = train_acc / train_data_size

        avg_valid_loss = valid_loss / valid_data_size
        avg_valid_acc = valid_acc / valid_data_size

        record.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])

        if avg_valid_acc > best_acc:
            best_acc = avg_valid_acc
            best_epoch = epoch + 1
            print("Best Accuracy for validation : {:.4f} at epoch {:03d}".format(best_acc, best_epoch))
            torch.save(model, 'output/model_%s_%s.pth' % (epoch + 1, best_acc))

        epoch_end = time.time()

        print("Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, Validation: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s".format(
                epoch + 1, avg_valid_loss, avg_train_acc * 100, avg_valid_loss, avg_valid_acc * 100,
                epoch_end - epoch_start))

    return model, record


if __name__ == "__main__":
    num_epochs = config.NUM_EPOCHS
    train_dir = "train_data/data-min3.h5"

    batch_size = config.BATCH_SIZE
    num_classes = config.NUM_CLASSES

    # numpy如何构建dataset
    f = h5py.File(train_dir, 'r')
    x = f['x_train']
    y = f['y_train']
    print(type(x), type(y))
    train_datasets = H5Dataset(x, y)
    all_data_size = len(train_datasets)
    train_data_size = int(0.9 * all_data_size)
    train_db, val_db = torch.utils.data.random_split(train_datasets, [train_data_size, all_data_size - train_data_size])
    print('db1:', len(train_db), 'db2:', len(val_db))

    train_loader = torch.utils.data.DataLoader(train_db, batch_size=batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_db, batch_size=batch_size, shuffle=True)
    valid_data_size = len(val_db)
    print(train_data_size)

    resnet50 = models.resnet50(pretrained=True)
    print('before:{%s}\n' % resnet50)
    for param in resnet50.parameters():
        param.requires_grad = False
    fc_inputs = resnet50.fc.in_features
    resnet50.fc = nn.Sequential(
        nn.Linear(fc_inputs, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, 10),
        # nn.LogSoftmax(dim=1),
        nn.Softmax(dim=1)
    )
    print('after:{%s}\n' % resnet50)
    loss_func = nn.CrossEntropyLoss()
    # loss_func = nn.NLLLoss()
    optimizer = opt.Adam(resnet50.parameters(), lr=0.01, weight_decay=0.1)
    trained_model, record = train_and_valid(resnet50, loss_func, optimizer, num_epochs)
    torch.save(record, config.TRAINED_MODEL)
